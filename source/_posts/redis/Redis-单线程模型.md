---
title: Redis-单线程模型
date: 2021-07-02 21:41:24
index_img: /img/cover/Redis.jpg
cover: /img/cover/Redis.jpg
tags:
- 单线程模型
categories:
- Redis
updated:
type:
comments:
description:
keywords:
top_img:
mathjax:
katex:
aside:
aplayer:
highlight_shrink:
---

### 参考文献

* [了解redis的单线程模型工作原理？一篇文章就够了](https://blog.csdn.net/qq_38601777/article/details/91325622)
* [REDIS 单线程模型介绍](https://www.cnblogs.com/yrjns/p/12517784.html)
* [redis单线程模型](https://www.cnblogs.com/ryjJava/p/14268079.html)

#### Redis为什么采用单线程?

* **从性能角度来看**
  * 单线程避免了上下文频繁切换问题,效率高;
* **从内部结构设计角度来看**
  * Redis是基于Reactor模式开发了自己的网络事件处理器,这个处理器被称为**文件处理器(File Event Handler)**.而这个文件事件处理器是单线程的,所以才叫Redis的单线程模型,这也决定了Redis的单线程;

#### Redis的单线程模型

> Redis单线程模型中最核心的就是**文件事件处理器**

<img src="http://www.chenjunlin.vip/img/redis/Redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png" alt="img" style="zoom:67%;" />

###### 文件事件处理器

* 文件事件处理器结构包含4个部分:**Socket**,**I/O多路复用程序**,**文件事件分派器(`Dispather`)**,**事件处理器(`Handler`)**;
* `I/O`多路复用程序会同时监听多个`socket`，当被监听的`socket`准备好执行`accept`、`read`、`write`、`close`等操作时，与这些操作相对应的文件事件就会产生。`IO`多路复用程序会把所有产生事件的`socket`压入一个队列中，然后有序地每次仅一个`socket`的方式传送给文件事件分派器，文件事件分派器接收到`socket`之后会根据`socket`产生的事件类型调用对应的事件处理器进行处理。
* 事件处理器分为以下几种:
  * **连接应答处理器**: 用于处理客户端的连接请求;
  * **命令请求处理器**: 用于执行客户端传递过来的命令,比如常见的`set`,`lpush`等;
  * **命令回复处理器**: 用于返回客户端命令的执行结果,比如`set`,`get`等命令的结果;
* 事件的种类: 
  * **AE_READABLE**: 与两个事件处理器结合使用.
    * 当客户端连接服务器端时,服务端会将**连接应答处理器**与`Socket`的**AE_READABLE**事件关联起来;
    * 当客户端向服务端发送命令的时候,服务器端将**命令请求处理器**与**AE_READABLE**事件关联起来;
  * **AE_WRITABLE **: 当服务端有数据需要回传给客户端时,服务端将**命令回复处理器**与`Socket`的**AE_WRITABLE **事件关联起来;

##### Redis的客户端与服务器端的交互过程

![img](http://www.chenjunlin.vip/img/redis/Redis%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B.jpg)

* 在Redis启动及初始化的时候,Redis会(预先)将**连接应答处理器**跟**AE_READABLE事件**关联起来,接着如果一个客户端向Redis发起连接,此时就会产生一个**AE_READABLE事件**,然后由**连接应答处理器**来处理跟客户端建立连接,创建客户端对应的socket,同时将这个Socket的**AE_READABLE事件**跟**命令请求处理器**关联起来;
* 当客户端向Redis发起请求的时候(不管是读请求还是写请求,都一样),首先就会在之前创建的客户端对应的Socket上产生一个**AE_READABLE事件**,然后**I/O多路复用程序**会监听到在之前创建的客户端对应的Socket上产生了一个**AE_READABLE事件**,接着把这个Socket放入一个队列中排队,然后由**文件事件分派器**从队列中获取Socket交给对应的**命令请求处理器**来处理(因为之前在Redis启动并进行初始化的时候就已经预先将**AE_READABLE**事件跟**命令请求处理器**关联起来了).之后**命令请求处理器**就会从之前创建的客户端对应的Socket中读取请求相关的数据,然后在自己的内存中进行执行和处理;
*  当客户端请求处理完成,Redis这边也准备好了给客户端的响应数据之后,就会(预先)将Socket的**AE_WRITABLE**事件跟**命令回复处理器**关联起来,当客户端这边准备好读取响应数据时,就会在之前创建的客户端对应的Socket上产生一个**AE_WRITABLE事件**,然后**IO多路复用程序**会监听到在之前创建的客户端对应的Socket上产生了一个**AE_WRITABLE事件**,接着把这个Socket放入一个队列中排队,然后由**文件事件分派器**从队列中获取Socket交给对应的**命令回复处理器**来处理(因为之前在Redis这边准备好给客户端的响应数据之后就已经预先将**AE_WRITABLE事件**跟**命令回复处理器**关联起来了),之后**命令回复处理器**就会向之前创建的客户端对应的Socket输出/写入准备好的响应数据,最终返回给客户端,供客户端来读取;

#### 为什么Redis使用单线程模型还能保证高性能？

* **纯内存访问**: Redis将所有数据放在内存中,内存的响应时长大约为100纳秒,这是Redis的QPS过万的重要基础;

* **使用非阻塞式I/O**

  * 什么是阻塞式I/O
    * 当我们调用 Scoket 的读写方法，默认它们是阻塞的。
    * `read()` 方法要传递进去一个参数 n，表示读取这么多字节后再返回，如果没有读够 n 字节线程就会阻塞，直到新的数据到来或者连接关闭了,`read()` 方法才可以返回,线程才能继续处理。
    * `write()` 方法会首先把数据写到系统内核为Socket 分配的写缓冲区中，当写缓存区满溢，即写缓存区中的数据还没有写入到磁盘，就有新的数据要写道写缓存区时,`write()` 方法就会阻塞，直到写缓存区中有空闲空间。
  * 什么是非阻塞式 I/O
    * 非阻塞 I/O 在 Socket 对象上提供了一个选项`Non_Blocking` ，当这个选项打开时，读写方法不会阻塞，而是能读多少读多少，能写多少写多少。
    * 能读多少取决于内核为 Socket 分配的读缓冲区的大小，能写多少取决于内核为 Socket 分配的写缓冲区的剩余空间大小。读方法和写方法都会通过返回值来告知程序实际读写了多少字节数据。
    * 有了非阻塞 IO 意味着线程在读写 IO 时可以不必再阻塞了，读写可以瞬间完成然后线程可以继续干别的事了。

* **使用I/O多路复用**

  > 文件描述符(fd)：内核（Kernel）利用文件描述符（File Descriptor）来访问文件。文件描述符是非负整数。打开现存文件或新建文件时，内核会返回一个文件描述符。读写文件也需要使用文件描述符来指定待读写的文件。

  ![img](http://www.chenjunlin.vip/img/linux/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png)

  * 多路 I/O 复用模型是利用`select`、`poll`、`epoll`可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（`epoll`是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。

  *  `IO`复用只需要阻塞在`select`，`poll`或者`epoll`，可以同时处理和管理多个连接。缺点是当`select`、`poll`或者`epoll` 管理的连接数过少时，这种模型将退化成阻塞`IO` 模型。并且还多了一次系统调用：一次`select`、`poll`或者`epoll` 一次`recvfrom`。

  * `select`、`poll`、`epoll` 区别：

    | 最大连接数 | FD剧增后带来的IO效率问题                                     | 消息传递方式                                                 |                                                              |
    | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | select     | 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64 | 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 | 内核需要将消息传递到用户空间，都需要内核拷贝动作             |
    | poll       | 基于链表来存储的，没有最大连接数的限制                       | 同上                                                         | 内核需要将消息传递到用户空间，都需要内核拷贝动作             |
    | `epoll`    | 接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接   | 因为`epoll`内核中实现是根据每个`fd`上的`callback`函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用`epoll`没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 | 利用`mmap()`文件映射内存加速与内核空间的消息传递；即`epoll`使用`mmap`减少复制开销 |

* **单线程避免了线程切换和竞态产生的消耗。**

  * 单线程能带来几个好处：
    - 第一，单线程可以简化数据结构和算法的实现。并发数据结构实现不但困难而且开发测试比较麻烦;
    
    - 第二，单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手;
    
  * 单线程的问题：对于每个命令的执行时间是有要求的。如果 某个命令执行过长，会造成其他命令的阻塞，所以Redis 适用于那些需要快速执行的场景。
  
* **使用`epoll`模型**

  > `epoll`是Linux提供的系统实现，核心方法只有三个`epoll_create`、`epollctl`、`epollwait`。`epoll`效率高，是因为基于红黑树、双向链表、事件回调机制。

  ![img](http://www.chenjunlin.vip/img/linux/epoll%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png)

  * `epoll_create`

    ```
    epoll_create(int size)
    核心功能：
    1.创建一个epoll文件描述符
    2.创建eventpoll，其中包含红黑树cache和双向链表
    ```

    * 参数size并不是限制了`epoll`所能监听的文件描述符最大个数，只是对内核初始分配内部数据结构的一个建议。在Linux 2.6.8后，size 参数被忽略，但是必须传一个比 0 大的数。调用`epoll_create`后，会占用一个`fd`值。在Linux下可以查看`/proc/$$/fd/` 文件描述符。使用完，需要调用close关闭。

  * `epollctl`

    ```
    int epollctl(int epfd, int op, int fd, struct epollevent *event)；
    核心功能：
    1.对指定描述符fd执行op的绑定操作
    2.把fd写入红黑树，同时在内核注册回调函数
    ```

    * op操作类型，用三个宏`EPOLL_CTL_ADD`，`EPOLL_CTL_DEL`，`EPOLL_CTL_MOD`，来分别表示增删改对`fd`的监听。

  * `epollwait`

    ```
    int epollwait(int epfd, struct epollevent *events, int maxevents, int timeout);
    核心功能：
    1.获取epfd上的io事件
    ```

    * 参数`events`是就绪事件，用来得到想要获得的事件集合。`maxevents`表示的events有多大，`maxevents`的值必须大于0，参数`timeout`是超时时间。`epollwait`会阻塞，直到一个文件描述符触发了事件，或者被一个信号处理函数打断，或者timeout超时。返回值是需要处理的`fd`数量。
    
  * **使用`epoll`模型优点**
  
      * `epoll`创建的红黑树保存所有`fd`，没有大小限制，且增删查的复杂度`O(logN)`
      * 基于callback，利用系统内核触发感兴趣的事件
      * 就绪列表为双线链表时间复杂度O(1)
      * 应用获取到的`fd`都是真实发生IO的`fd`，与select 和 poll 需要不断轮询判断是否可用相比，能避免无用的内存拷贝
