---
title: Kafka面试题(收集未整理)
date: 2021-06-03 22:56:20
index_img: /img/cover/Kafka.jpg
cover: /img/cover/Kafka.jpg
tags:
- 中间件
- 面试题
categories:
- Kafka
---

#### 参考文献

* [Kafka常见面试题](https://blog.csdn.net/qq_28900249/article/details/90346599)
* [Kafka 常见面试题整理](https://mp.weixin.qq.com/s/pShUnc1pyjg3alIwxDFkPw)
* [最新基准测试：Kafka、Pulsar 和 RabbitMQ 哪个最快？](https://mp.weixin.qq.com/s/VwyYnhZzc17u64IO1RZaWw)
* [kafka专题：kafka的消息丢失、重复消费、消息积压等线上问题汇总及优化](https://blog.csdn.net/qq_45076180/article/details/111561984)
* [Kafka在中信建投的实战](https://mp.weixin.qq.com/s/lXdMMedZCS-gvkzYajx3EA)

#### 什么是Kafa

> Kafka是分布式发布-订阅消息系统，它最初是由LinkedIn公司开发的，之后成为Apache项目的一部分，Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理流式数据。
>
> Kafka是scala语言开发，运行在JVM上
>
> Kafka是由LinkedIn开发的一个分布式的消息系统，使用Scala编写，它以高扩展性、高吞吐、低延迟以及高可靠性而被广泛使用。当前很多分布式处理系统如Storm、Spark、Flink都支持与Kafka集成用于搭建实时数据处理平台。另外，大多ELK平台也是基于Kafka搭建，以Filebeat、Logstash等将日志数据、设备日志等收集到Kafka，经过计算处理后存入Elasticsearch做统计或者图表。

#### 请说明什么是传统的消息传递方法?

> 传统的消息传递方法包括两种：
>
> * 队列：在队列中，一组用户可以从服务器中读取消息，每条消息都发送给其中一个人。
>
> - 发布-订阅：在这个模型中，消息被广播给所有的用户。

#### 请说明Kafka相对传统技术有什么优势

> Apache Kafka与传统的消息传递技术相比优势之处在于：
>
> * 快速:单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作。
>
> * 可伸缩:在一组机器上对数据进行分区和简化，以支持更大的数据
>
> * 持久:消息是持久性的，并在集群中进行复制，以防止数据丢失。
>
> * 设计:它提供了容错保证和持久性

#### 为什么要使用 kafka，为什么要使用消息队列

> **缓冲和削峰**：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就可以按照自己的节奏进行慢慢处理。
>
> **解耦和扩展性**：项目开始的时候，并不能确定具体需求。消息队列可以作为一个接口层，解耦重要的业务流程。只需要遵守约定，针对数据编程即可获取扩展能力。
>
> **冗余**：可以采用一对多的方式，一个生产者发布消息，可以被多个订阅topic的服务消费到，供多个毫无关联的业务使用。
>
> **健壮性**：消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。
>
> **异步通信**：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

#### Kafka为什么需要复制?

> Kafka的信息复制确保了任何已发布的消息不会丢失，并且可以在机器错误、程序错误或更常见些的软件升级中使用。

#### Kafka RabbitMQ ZeroMQ ActiveMQ Redis对比

> **RabbitMQ**
>
> * Erlang编写
>   支持很多的协议：AMQP，XMPP, SMTP, STOMP
> * 非常重量级，更适合于企业级的开发
> * 发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。
>
> **Redis**
>
> * 基于Key-Value对的NoSQL数据库
> * 入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；
> * 出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。
>
> **ZeroMQ**
>
> * 号称最快的消息队列系统，尤其针对大吞吐量的需求场景。
>
> * 高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。
>
> * 具有一个独特的非中间件的模式，不需要安装和运行一个消息服务器或中间件
>
> * ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。
>
> **ActiveMQ**
>
> * 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。
> * 类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。
> **Kafka/Jafka**
>
> * 高性能跨语言分布式发布/订阅消息队列系统
> * 快速持久化，可以在O(1)的系统开销下进行消息持久化；
> * 高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；
> * 完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；
> * 支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过
> * Hadoop的并行加载机制统一了在线和离线的消息处理。
> * 一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。

#### **Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么**?

> **ISR**:In-Sync Replicas 副本同步队列
> **AR**:Assigned Replicas 所有副本
> ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间`replica.lag.time.max.ms`和延迟条数`replica.lag.max.messages`两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR

#### Kafka 中的 HW、 LEO 等分别代表什么？

> **LEO（Log End Offset）**：每个副本的最后一个offset
>
> **HW（High Watermark）**：所有副本的最小LEO
>
> **follower故障时**：follower会被踢出isr，恢复后，follower读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步，等follower的LEO大于等于该partition的HW后，就可以重新加入isr。
>
> **leader故障时：**leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的， 数据一致性， 其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据。

#### **Kafka 中是怎么体现消息顺序性的？**

> kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
>
> 整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.

#### **kafka中的broker 是干什么的**?

> broker 是消息的代理，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉取指定Topic的消息，然后进行业务处理，broker在中间起到一个代理保存消息的中转站。

#### Kafka 中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？

> **分区器**：可以给消息指定传入分区
>
> **序列化器**：将生产者消息序列化，可以被网络传输
>
> **拦截器**：可以在消息传入Kafka前和producer回调函数返回前对消息进行简单的处理

#### **Kafka 生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？**

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/jygPM3bcIibmTLBI8K38OOswzkia7OvlKaMcSuVpf07E20FLMeuibqzXH0Q3RsFq9NYm8sWUfPxib9WNglRuibl7aicg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> **main线程负责**：拦截器—>序列化器—>分区器
>
> **sender线程负责**：将分区后的数据发送给对应分区.

#### **有哪些情形会造成重复消费？那些情景会造成消息漏消费 ？**

> **重复消费**：先处理数据，再提交offset
>
> **消息漏消费**：先提交offset，再处理数据
>
> Kafka消息消费有两个consumer接口，Low-level API和High-level API：
>
> Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；
>
> High-level API：封装了对parition和offset的管理，使用简单；
>
> 如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就会丢失；
>
> 消息的重复消费，即要解决消费时的幂等性。解决思路：
>
> 生产者生产数据时，添加一个全局唯一的id，处理时如果发现一个id已经被处理，那就忽略这条消息
>
> 如果消费操作是向数据库中插入数据，可以利用数据库的唯一键。

#### **Kafka 有内部的 topic 吗？如果有是什么？有什么所用？**

> consumer 默认将 offset 提交到Kafka 一个内置的 topic 中，该 topic 为__consumer_offsets。
>
> **它存在的目的之一就是保存** **consumer** **提交的位移**。

#### **kafka中的 zookeeper 起到什么作用，可以不用zookeeper么**

> zookeeper 是一个分布式的协调组件，早期版本的kafka用zk做meta信息存储，consumer的消费状态，group的管理以及 offset的值。考虑到zk本身的一些因素以及整个架构较大概率存在单点问题，新版本中逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的group coordination协议，也减少了对zookeeper的依赖，
>
> 但是broker依然依赖于ZK，zookeeper 在kafka中还用来选举controller 和 检测broker是否存活等等

#### **kafka follower如何与leader同步数据**

> Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求All Alive Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下，如果leader挂掉，会丢失数据，kafka使用ISR的方式很好的均衡了确保数据不丢失以及吞吐率。Follower可以批量的从Leader复制数据，而且Leader充分利用磁盘顺序读以及send file(zero copy)机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了Follower与Leader的消息量差。

#### **什么情况下一个 broker 会从 isr中踢出去**

> leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护 ，如果一个follower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其重ISR中移除 

#### **kafka 为什么那么快**

> * Cache Filesystem Cache PageCache缓存
>
> * 顺序写 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。
>
> * Zero-copy 零拷技术减少拷贝次数
>
> * Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。
>
> * Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。

#### **kafka producer如何优化打入速度**

> * 增加线程
>
> * 提高 batch.size
>
> * 增加更多 producer 实例
>
> * 增加 partition 数
>
> * 设置 acks=-1 时，如果延迟增大：可以增大 num.replica.fetchers（follower 同步数据的线程数）来调解；
>
> * 跨数据中心的传输：增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。

#### **如果leader crash时，ISR为空怎么办**

> kafka在Broker端提供了一个配置参数：unclean.leader.election,这个参数有两个值：
> true（默认）：允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。
> false：不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。

#### **kafka中consumer group 是什么概念**

> 同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。

#### **kafka的message格式是什么样的**

> 一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成
>
> header部分由一个字节的magic(文件格式)和四个字节的CRC32(用于判断body消息体是否正常)构成。
>
> 当magic的值为1的时候，会在magic和crc32之间多一个字节的数据：attributes(保存一些相关属性，
>
> 比如是否压缩、压缩格式等等);如果magic的值为0，那么不存在attributes属性
>
> body是由N个字节构成的一个消息体，包含了具体的key/value消息

#### **Kafka中的消息是否会丢失和重复消费？**

> 要确定Kafka的消息是否丢失或重复，从两个方面分析入手：消息发送和消息消费。
>
> 1、消息发送
>
> Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。Kafka通过配置request.required.acks属性来确认消息的生产：
>
> 0---表示不进行消息接收是否成功的确认；
> 1---表示当Leader接收成功时确认；
> -1---表示Leader和Follower都接收成功时确认；
> 综上所述，有6种消息生产的情况，下面分情况来分析消息丢失的场景：
>
> （1）acks=0，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，消息可能丢失；
>
> （2）acks=1、同步模式下，只有Leader确认接收成功后但挂掉了，副本没有同步，数据可能丢失；
>
> 2、消息消费
>
> Kafka消息消费有两个consumer接口，Low-level API和High-level API：
>
> Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；
>
> High-level API：封装了对parition和offset的管理，使用简单；
>
> 如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“诡异”的消失了；
>
> 解决办法：
>
>* 针对消息丢失：同步模式下，确认机制设置为-1，即让消息写入Leader和Follower之后再确认消息发送成功；异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；
>     
>* 针对消息重复：将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。

#### **为什么Kafka不支持读写分离？**

> 在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。
>
> Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:
>
> (1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。
>
> (2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。

#### **Kafka中是怎么体现消息顺序性的？**

> kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
> 整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.

#### **kafka如何实现延迟队列？**

> Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。
>
> 底层使用数组实现，数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask.
>
> Kafka中到底是怎么推进时间的呢？Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的TimingWheel专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O(1)的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。

#### **Kafka 分区分配的概念？**

> Kafka提供了消费者客户端参数 partition.assignment.strategy 用来设置消费者与订阅主题之间的分区分配策略，Kafka有两种分配策略：
>
> **RangeAssignor(默认)**
>
> Range 范围分区策略是对每个 topic 而言的。首先对同一个 topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。假如现在有 10 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6,7,8,9；消费者排序完之后将会是C1-0,C2-0,C3-0。通过 partitions数/consumer数来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。
>
> Range 范围分区的弊端：
>
> 针对 1 个 topic 而言，C1-0消费者多消费1个分区影响不是很大。如果有 N 多个 topic，那么针对每个 topic，消费者 C1-0 都将多消费 1 个分区，topic越多，C1-0 消费的分区会比其他消费者明显多消费 N 个分区。这就是 Range 范围分区的一个很明显的弊端了。
>
> **RoundRobinAssignor**
>
> RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照 hashcode 进行排序，最后通过轮询算法来分配 partition 给到各个消费者。
>
> 如果想要使用RoundRobin 轮询分区策略，必须满足如下两个条件：
>
> 每个消费者订阅的主题，必须是相同的
>
> 每个主题的消费者实例都是相同的。(即：上面的第一种情况，才优先使用 RoundRobin 轮询分区策略)

#### 什么时候触发分区分配(Rebalance )策略？

> 当出现以下几种情况时，Kafka 会进行一次分区分配操作，即 Kafka 消费者端的 Rebalance 操作
>
> - 同一个 consumer 消费者组 group.id 中，新增了消费者进来，会执行 Rebalance 操作
> - 消费者离开当期所属的 consumer group组。比如 主动停机 或者 宕机
> - 分区数量发生变化时(即 topic 的分区数量发生变化时)
> - 消费者主动取消订阅
>
> Kafka 消费端的 Rebalance 机制，规定了一个 Consumer group 下的所有 consumer 如何达成一致来分配订阅 topic 的每一个分区。而具体如何执行分区策略，就是上面提到的 Range 范围分区 和 RoundRobin 轮询分区 两种内置的分区策略。Kafka 对于分区分配策略这块，也提供了可插拔式的实现方式，除了上面两种分区分配策略外，我们也可以创建满足自己使用的分区分配策略，即：自定义分区策略。

#### **Kafka 的哪些设计让它有如此高的性能？**

> **批量处理**
>
> 传统消息中间件的消息发送和消费整体上是针对单条的。对于生产者而言，它先发一条消息，然后broker返回ACK表示已接收，这里产生2次rpc；对于消费者而言，它先请求接受消息，然后broker返回消息，最后发送ACK表示已消费，这里产生了3次rpc（有些消息中间件会优化一下，broker返回的时候返回多条消息）。而Kafka采用了批量处理：生产者聚合了一批消息，然后再做2次rpc将消息存入broker，这原本是需要很多次的rpc才能完成的操作。假设需要发送1000条消息，每条消息大小1KB，那么传统的消息中间件需要2000次rpc，而Kafka可能会把这1000条消息包装成1个1MB的消息，采用2次rpc就完成了任务。这一改进举措一度被认为是一种“作弊”的行为，然而在微批次理念盛行的今日，其它消息中间件也开始纷纷效仿。
>
> ------
>
> **客户端优化**
>
> 这里接着批量处理的概念继续来说，新版生产者客户端摒弃了以往的单线程，而采用了双线程：主线程和Sender线程。主线程负责将消息置入客户端缓存，Sender线程负责从缓存中发送消息，而这个缓存会聚合多个消息为一个批次。有些消息中间件会把消息直接扔到broker。
>
> ------
>
> **消息压缩**
>
> Kafka支持多种消息压缩方式（gzip、snappy、lz4）。对消息进行压缩可以极大地减少网络传输 量、降低网络 I/O，从而提高整体的性能。消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。
>
> ------
>
> **建立索引，方便快速定位查询**
>
> 每个日志分段文件对应了两个索引文件，主要用来提高查找消息的效率，这也是提升性能的一种方式。
>
> ------
>
> **分布式架构**
>
> 很多人会忽略掉这个因素，其实分区也是提升性能的一种非常有效的方式，这种方式所带来的效果会比前面所说的日志编码、消息压缩等更加的明显。分区在其他分布式组件中也有大量涉及，至于为什么分区能够提升性能这种基本知识在这里就不在赘述了。
>
> ------
>
> **顺序写盘**
>
> 操作系统可以针对线性读写做深层次的优化，比如预读(read-ahead，提前将一个比较大的磁盘块读入内存) 和后写(write-behind，将很多小的逻辑写操作合并起来组成一个大的物理写操作)技术。Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息，这种方式属于典型的顺序写盘的操作，所以就算 Kafka 使用磁盘作为存储介质，它所能承载的吞吐量也不容小觑。
>
> ------
>
> **页缓存**
>
> 为什么Kafka性能这么高？当遇到这个问题的时候很多人都会想到上面的顺序写盘这一点。其实在顺序斜盘前面还有页缓存（PageCache）这一层的优化。
>
> 页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘 I/O 的操作。具体 来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。为了弥补性 能上的差异，现代操作系统越来越“激进地”将内存作为磁盘缓存，甚至会非常乐意将所有可用的内存用作磁盘缓存，这样当内存回收时也几乎没有性能损失，所有对于磁盘的读写也 将经由统一的缓存。
>
> 当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页 (page)是否在页缓存(pagecache)中，如果存在(命中)则直接返回数据，从而避免了对物理磁盘的 I/O 操作;如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后将数据写入对应的页。被修改过后的页也就变成了脏页，操作系统会在合适的时间把脏页中的 数据写入磁盘，以保持数据的一致性。
>
> 对一个进程而言，它会在进程内部缓存处理所需的数据，然而这些数据有可能还缓存在操 作系统的页缓存中，因此同一份数据有可能被缓存了两次。并且，除非使用 Direct I/O 的方式， 否则页缓存很难被禁止。此外，用过 Java 的人一般都知道两点事实：对象的内存开销非常大， 通常会是真实数据大小的几倍甚至更多，空间使用率低下；Java 的垃圾回收会随着堆内数据的增多而变得越来越慢。基于这些因素，使用文件系统并依赖于页缓存的做法明显要优于维护一 个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。如此，我们可以在 32GB 的机器上使用 28GB 至 30GB 的内存而不用担心 GC 所带来的性能问题。此外，即使 Kafka 服务重启， 页缓存还是会保持有效，然而进程内的缓存却需要重建。这样也极大地简化了代码逻辑，因为 维护页缓存和文件之间的一致性交由操作系统来负责，这样会比进程内维护更加安全有效。
>
> Kafka 中大量使用了页缓存，这是 Kafka 实现高吞吐的重要因素之一。虽然消息都是先被写入页缓存，然后由操作系统负责具体的刷盘任务的。
>
> ------
>
> **零拷贝**
>
> Kafka使用了Zero Copy技术提升了消费的效率。前面所说的Kafka将消息先写入页缓存，如果消费者在读取消息的时候如果在页缓存中可以命中，那么可以直接从页缓存中读取，这样又节省了一次从磁盘到页缓存的copy开销。另外对于读写的概念可以进一步了解一下什么是写放大和读放大。
>
> 1. **分布式存储架构**
> 2. **磁盘顺序读写**
>    kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾，不会写入文件中的某个位置(随机写)保证了磁盘顺序写。
> 3. **读写数据的批量batch处理以及压缩传输**
> 4. **数据传输的零拷贝**
>
> ![在这里插入图片描述](https://img-blog.csdnimg.cn/20201225212146201.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1MDc2MTgw,size_16,color_FFFFFF,t_70)

#### **Kafka消费者角度考虑是拉取数据还是推送数据？**

> 拉取数据

#### **Kafka中的数据是有序的吗？**

> 单分区内有序。
>
> 多分区，分区与分区间无序。

#### **Kafka过期数据清理**

> 保证数据没有被引用（没消费过）
>
> 日志清理保存的策略只有delete和compact两种
>
> log.cleanup.policy=delete启用删除策略
>
> log.cleanup.policy=compact启用压缩策略

#### **Kafka单条日志传输大小是多大？**

> kafka对于消息体的大小默认为单条最大值是**1M**但是在我们应用场景中, 常常
>
> 会出现一条消息大于1M，如果不对kafka进行配置。则会出现生产者无法将消息推送到kafka或消费者无法去消费kafka里面的数据, 这时我们就要对kafka进行以下配置：**server.properties**
>
> ```
> replica.fetch.max.bytes: 1048576 broker可复制的消息的最大字节数, 默认为1M
> message.max.bytes: 1000012 kafka 会接收单个消息size的最大限制， 默认为1M左右
> ```
>
> 注意：message.max.bytes必须**小于等于**replica.fetch.max.bytes，否则就会导致replica之间数据同步失败。

#### **Kafka消息数据积压，Kafka消费能力不足怎么处理？**

> 如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）
>
> 如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间<生产速度），使处理的数据小于生产的数据，也会造成数据积压。
>
> 线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致broker积压大量未消费消息。
> 解决方案：此种情况如果积压了上百万未消费消息需要紧急处理，可以修改消费端程序，让其将收到的消息快速转发到其他topic(可以设置很多分区)，然后再启动多个消费者同时消费新主题的不同分区。如图所示
> ![在这里插入图片描述](https://img-blog.csdnimg.cn/20201225204848118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1MDc2MTgw,size_16,color_FFFFFF,t_70)
>
> 由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息。
> 解决方案：此种情况可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题。这个死信队列，kafka并没有提供，需要整合第三方插件！

#### Kafka消息丢失

> kafka在生产端发送消息 和 消费端消费消息 时都可能会丢失一些消息
>
> ①：生产者消息丢失
> 生产者在发送消息时，会有一个ack机制，当ack=0 或者 ack=1时，都可能会丢消息。如下所示：
>
> * acks=0
>   表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息。大数据统计报表场景，对性能要求很高，对数据丢失不敏感的情况可以用这种。
>
> * acks=1
>   至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入。就可以继续发送下一条消息。这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。
>
> * acks=-1或all
>   这意味着leader需要等待所有备份(min.insync.replicas配置的备份个数)都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置。当然如果min.insync.replicas配置的是1则也可能丢消息，跟acks=1情况类似。
>
> ②：消费端消息丢失
>        消费端丢消息最主要体现在消费端offset的自动提交，如果开启了自动提交，万一消费到数据还没处理完，此时你consumer直接宕机了，未处理完的数据 丢失了，下次也消费不到了，因为offset已经提交完毕，下次会从offset出开始消费新消息。
>
> 解决办法是采用消费端的手动提交
>
> ```
>     //手动提交offset
>      /**
>          * 注意如果要使用手动提交offset，需要以下三点
>          * ①：配置文件配置手动提交方式
>          * ②：加上参数Acknowledgment ack
>          * ③：方法中使用ack.acknowledge();手动提交
>          */
>         ack.acknowledge();
> ```

#### Kafka重复消费

> * 强行kill线程，导致消费后的数据，offset没有提交，partition就断开连接。比如，通常会遇到消费的数据，处理很耗时，导致超过了Kafka的session timeout时间（0.10.x版本默认是30秒），那么就会re-blance重平衡，此时有一定几率offset没提交，会导致重平衡后重复消费。
>
> * 如果在close之前调用了consumer.unsubscribe()则有可能部分offset没提交，下次重启会重复消费。
>
> * Kafka数据重复Kafka设计的时候是设计了(at-least-once)至少一次的逻辑，这样就决定了数据可能是重复的，Kafka采用基于时间的SLA(服务水平保证)，消息保存一定时间（通常为7天）后会被删除。
>
> * Kafka的数据重复一般情况下应该在消费者端，这时log.cleanup.policy = delete使用定期删除机制。
>

* **生产端消息重复发送**

  > * 发送消息如果配置了重试机制，比如由于网络波动，生产者未得到broker收到了消息的响应，就会触发重试机制，3秒后再次发送此消息。broker之前已经收到过这个消息，但生产者由于触发了重试机制，就导致了消息的重复发送。那么broker就会在磁盘缓存多条同样的消息，消费端从broker拉取消息时，就会造成重复消费。
  >
  > * 注意：kafka新版本已经在broker中保证了接收消息的幂等性（比如2.4版本），只需在生产者加上参数 props.put(“enable.idempotence”, true) 即可，默认是false不开启。
  >
  > * 新版kafka的broker幂等性具体实现原理：kafka每次发送消息会生成PID和Sequence Number，并将这两个属性一起发送给broker，broker会将PID和Sequence Number跟消息绑定一起存起来，下次如果生产者重发相同消息，broker会检查PID和Sequence Number，如果相同不会再接收。
  >   * PID：每个新的 Producer 在初始化的时候会被分配一个唯一的 PID，这个PID对用户完全是透明的。生产者如果重启则会生成新的PID。
  >   * Sequence Number：对于每个 PID，该 Producer 发送到每个 Partition 的数据都有对应的序列号，这些序列号是从0开始单调递增的。

* 消费端消息重复消费

  > 对于消费端消息的重复消费问题，如果消费端拉取了一部分数据，消费完毕后，准备执行手动提交（或自动提交）时，消费者挂掉了！此时offset还未提交呢，那么当服务重启时，还是会拉取相同的一批数据重复处理！造成消息重复消费

* 无论是生产者还是消费者的重复消息，一般都会在消费端卡死，做幂等性处理。幂等性可以用redis的setnx分布式锁来实现。比如操作订单消息，可以把订单id作为key，在消费消息时，通过setnx命令设置一下，offset提交完成后，在redis中删除订单id的key。setnx命令保证同样的订单消息，只有一个能被消费，可有效保证消费的幂等性！

#### Kafka、RabbitMQ 和 Pulsar 比较

> - **吞吐量**：Kafka 在三个系统中的吞吐量最高，是 RabbitMQ 的 15 倍，Pulsar 的 2 倍。
> - **延迟**：Kafka 在较高的吞吐量下提供了最低的延迟，同时还提供了强大的持久性和高可用性。在默认配置下，Kafka 在所有延迟基准测试中都要比 Pulsar 快，而且，当设置为 fsync 每条消息时，一直到 p99.9 百分位，它都更快。RabbitMQ 可以实现比 Kafka 更低的端到端延迟，但只能在吞吐量低很多的情况下。
> - **成本 / 复杂性**：成本往往是性能的逆函数。作为具有最高稳定吞吐量的系统，由于其高效的设计，Kafka 提供了所有系统中最好的价值（即每字节写入成本）。事实上，Twitter 的 Kafka 之旅远离了像 Pulsar 这样的基于 BookKeeper 的架构，这证实了我们的观察：Kafka 相对较少的移动部件显著降低了它的成本（在 Twitter 的情况下高达 75%）。此外，将 ZooKeeper 从 Apache Kafka 中移除的工作正在进行中，这进一步简化了 Kafka 的架构。
>
> **kafka相对于rocketMQ、rabbitMQ来说，与它们最大的区别就是分布式存储，这也是kafka高性能的最主要原因**。使用分布式存储理念，一个主题下多个分区，同时可以被多个消费者和生产者去使用，也增加了接受消息和消费消息的能力！

#### 顺序消息

> kafka想要保证消息顺序，是需要牺牲一定性能的，方法就是一个消费者，消费一个分区，可以保证消费的顺序性。但也仅限于消费端消费消息的有序性，无法保证生产者发送消息有序。
> 比如：如果发送端配置了重试机制，kafka不会等之前那条消息完全发送成功才去发送下一条消息，这样可能会出现，发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了。发送端消息发送已经乱序，到了消费端消费时，自然无法保证顺序！
> 如果一定要保证生产-消费全链路消息有序，发送端需要同步发送，ack回调不能设置为0。且只能有一个分区，一个消费者进行消费，但这样明显有悖于kafka的高性能理论！
>
> 问题：如何在多个分区中保证消息顺序和消息处理效率呢？
>
> 首先使用多个分区，消息可以被发送端发送至多个分区，保证消息发送的效率。然后在消费端在拉消息时使用ConutdownLunch来记录一组有序消息的个数。如果达到个数，说明已拉取到完整的一组有序消息。然后在消费端根据消息序号进行排序，消费端将排好序的消息发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息。即可最大程度上既保证顺序又保证效率！

#### 延时消息

> 延时队列存储的对象是延时消息。所谓的“延时消息”是指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费，延时队列的使用场景有很多， 比如 ：
>
> 在订单系统中， 一个用户下单之后通常有 30 分钟的时间进行支付，如果 30分钟之内没有支付成功，那么这个订单将进行异常处理，这时就可以使用延时队列来处理这些订单了。订单完成1小时后通知用户进行评价。但kafka没有提供延时消息功能，可以用rocketmq、rabbitmq都做延时消息。
> 
> 如果一定要用kafka实现延时消息呢？
> 
>实现思路：发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中（topic_1s，topic_5s，topic_10s，…topic_2h，这个一般不能支持任意时间段的延时），然后通过定时器进行轮训消费这些topic，查看消息是否到期，如果到期就把这个消息发送到具体业务处理的topic中，队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，如果到了就转发，如果还没到这一次定时任务就可以提前结束了。

#### 消息回溯

> 如果某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费，可以指定从多久之前的消息回溯消费，这种可以用consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费，完成消息的回溯消费！

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/GI1YdwAnLsVLCrhlDmN73iadGviaddKCha0Nv3vas63jPjAYvoMW2YTiaC6uic6EVFDnfv5udNnGZkJkiaOuy5XiaP1Q/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

>
> Kafka在可靠性、可用性、扩展性、性能方面有很大优势，尤其是百万级QPS吞吐量让其迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。
>
> RocketMQ是阿里贡献给Apache的分布式消息系统，支持事务消息和过滤消费，性能低于Kafka。
>
> RabbitMQ由于开发语言和性能略低的问题，对于高吞吐量的场景并不适用，并且公司主流语言为java，人员对于Erlang语言的开发运维难度较大。

#### 在使用过程中遇到的问题

> Kafka在使用过程中不可避免的会遇到以下几个问题：
>
> 1、消息丢失：消息丢失会发生在生产端和消费端，生产端消息丢失是因为Broker未接收到生产端发送过来的消息或者未对消息持久化。消费端消息丢失是因为消费端未正确处理消息而提交了Offset。
>
> 2、重复消费：重复消费通常是指消费端正常消费而未提交Offset。比如，消费者处理超时导致消费者组re-balance，消费者组re-balance后有一定几率发生重复消费；消费者正常处理消息但提交Offset异常，这种情况也会发生重复消费。
>
> 3、消息积压：消息积压通常是因为数据量突然增大，消费端消费能力不足导致。这里还包括集群异常导致消费端无法正常消费而造成的积压。
>
> 4、顺序消息：Kafka只能保证单个分区内的消息的顺序性，对于全局顺序消息无法保证

#### 解决方案

> **消息丢失解决方案**
>
> 消息丢失在生产端和消费端均会发生。生产端Ack设置为0时，生产者无需等待Broker的写入确认，当Leader所在Broker异常时生产者发送的消息均丢失。ACK设置为1时，生产者只需等待Leader的写入确认，当Leader所在的Broker发生异常时Follower未同步的消息丢失。分区为单副本的情况下Broker宕机后会丢失消息。还有消费者设置了Offset自动提交，当消费者程序异常时也会丢失消息。解决丢失问题我们要从这三方面入手：
>
> 1、分区至少设置两个副本，保证分区高可用性。
>
> 2、设置ACK=-1，确保所有的副本均同步生产者的发送来的消息后再返回写入确认信息。做为消息系统使用必须设置为-1，日志收集类系统为提高吞吐量可以选择0或者1。
>
> 3、消费者Offset手动提交。避免在消费者发生异常后丢失未正确消费的消息。Kafka作为消息系统使用必须设置手动。手动提交有三种方式：
>
> * **同步手动提交偏移量**：同步模式下提交失败的时候会一直尝试提交，直到遇到无法重试的情况或者提交成功才会结束。这种方式消费者线程会发生阻塞，出现无法提交的情况时会导致消息积压。
>
> * **异步手动提交偏移量+回调函数**：异步手动提交offset时，消费者线程不会阻塞，提交失败的时候也不会进行重试，但可以配合回调函数在Broker做出响应的时候记录错误信息。
>
> * **异步+同步组合的方式提交偏移量**：消费者进行异步提交并且在关闭时进行同步提交，这样即使上一次的异步提交失败，还可通过同步提交来进行补救。

> **重复消费解决方案**
>
> 要解决重复消费就是保证消费者精确一次消费。有以下几种手段：
>
> 1、采用关系型数据库的事务性来保证精确一次更新，比如将消息的Offset或者唯一ID和下游状态更新放在一个库里，通过关系型数据事务性来保证精确一次更新。这种方式适用于消息量较小的系统。
>
> 2、为提高消费效率可以采用Redis等非关系数据库，将消息Offset或者业务主键放入Redis，消费者拉取消息后与Redis存储的消息信息做校验，根据校验结果决定是否消费拉取的消息。
>
> 3、使用状态机。通常在订单类业务系统中会涉及。使用状态机的前提是系统中的状态是有限的，比如一个订单有提交订单、支付（成功、失败）、发货、确认收货等几种状态。状态机的作用就是记录当前订单所处的状态并为下一次变更提供状态校验。比如状态机收到一个状态的变更，而此次变更为状态机记录的前一个状态，那么此次变更视则为无效变更。通过状态机，能够保证有限状态的幂等。
>
> 4、选择具有天然幂性的组件，比如Elasticsearch、Hbase等。

> **顺序消费问题解决方案**
>
> Kafka是一个队列，理论上消费顺序是不会错乱的。但是由于分布式的原因，Kafka的顺序消息只在单个分区内保证，整个主题消息的顺序性是无法保证的。因此，在多个消费者多分区的情况下，无法保证全局消息被顺序消费。
>
> 解决消息的顺序问题，可以将相同业务主键的消息发送到同一分区上，来保证相同业务主键消息的顺序性。Kafka在确定消息应该发送到那个分区是通过消息的Key取Hash决定的。因此在生产消息时指定消息的Key值（可以是订单ID或者业务组合ID），来保证具有相同业务属性的消息被发送到同一个分区。对于全局顺序消息可为主题设置单一分区来解决，但这种方式不适用数据量大的系统，容易造成数据积压。

> **消息积压问题解决方案**
>
> 在Kafka的使用中消息积压也是经常碰到的问题之一，比如消息量突然增大后消费者无法及时消费导致消息积压。通常的做法是在上生产之前先预估一个最大数据量，根据该数据量和消费速度来预分一个分区数，并在预上线环境进行压力测试，根据压测结果动态增加分区数，在数据无积压后再适当增加分区，来应对后期数据增长。
>
> 当遇到数据积压时，最简单的方式就动态扩展分区，并相应增加消费者进行消费，但这种方式存在破坏Message Key和分区对应关系的风险。另外一个途径是新建一个主题将积压的数据快速消费到新的主题，然后再增加新的消费者来消费新主题中的数据，缓解积压情况。
>
> 这里需要说明一下不是分区越多越好，分区数越多平均到每一个Broker上的数量越多，Broker压力也会越大堆内存占用也越多，在Broker宕机后Leader选举会占用更多时间，选举期间读写都会发生异常可能造成数据丢失。

#### 使用场景

> 日志收集
>
> 日志收集通常是从服务器中收集物理日志文件，通过Kafka将日志抽象为消息流，汇总后存入HDFS或者Elasticsearch用于后续处理或者表格展示等。公司采集的日志数据包括应用日志、中间件日志、操作系统日志、数据库日志、以及设备日志等，目前收集的日志每日增量在5TB左右。系统架构如图1所示：
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_png/GI1YdwAnLsUUazkd0VgeoKOU89BiaWfh3TUmcqNp3qtIUyxcafiaYDNcGKqpQK2rzElFESia9hWz0wC0AZrdMJUEA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
> 图 1 日志采集架构图
>
> 从架构图中可以看出Kafka作为日志汇总管道使用。Kafka不仅起到数据缓存、数据分发的作用，还可避免由于消费者程序故障造成数据丢失的风险。通过FileBeat或者Logstash将日志文件转换为消息发送到Kafka，经过一次转换或者计算后存入Elasticsearch或者不经过任何处理将原信息存入HDFS。设备日志主要是网络设备或者安全设备等，以syslog的形式发送到Logstash，Logstash初步处理后存入Kafka，再经过一次logstash转换存入Elasticsearch。存入Elasticsearch的数据经过计算后可做图表展示、智能运维、监控等，公司的ILOG系统、综合监控系统、SIEM平台等都是基于此框架实现的。
>
> 
>
> 在日志收集场景中，为了增加kafka吞吐率实际应用中可以将Ack参数设置为0或者1，消费者程序Offset提交可采用自动提交。对于海量的日志数据，丢失几条消息是可以容忍的。

> 实时数据处理-运维监控
>
> 实时数据处理是指通过处理引擎可以重复的去处理一种无限的数据集，这个数据集通常被称作“流数据”。通常说的流计算与实时计算的差别在于时效性，实时计算突出低延时。这类系统中Kafka必会用到，并且起到至关重要的作用。公司交易链路监控系统应用Kafka实现交易链路的拼接与告警，该系统从数据产生到监控告警，时延可达到秒级。系统架构如图2所示：
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_png/GI1YdwAnLsUUazkd0VgeoKOU89BiaWfh3bejGkN5FS1xpgicEb8PkGQRS6DlBTYMCUmynja6cAH9edGhs6mw3UjA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
> 图 2 交易链路预警
>
> 
>
> 图中天旦系统将采集模块的网络报文转换为消息发送到Kafka（原始报文），Logstash将原始报文做一些字段过滤处理存入Elasticsearch做详情展示。Flink实时读取Kafka中的消息计算交易耗时和进行报文拼接后再次发送到Kafka（结果报文），再由单独的消费程序存入Elasticsearch做预警和交易链路拼接。Flume将原始报文存入直接存入HDFS中做长期存储。公司每日收集报文量约为4TB左右，且主要集中在交易时段，Kafka层面遇到的问题为报文丢失和数据积压。
>
> 
>
> 系统上线初期由于数据量大Kafka集群性能不足，表现为机器负载特别高并且磁盘IO有大量wait，高负载导致Zookeeper心跳检测异常，分区Leader频繁切换，消费者被频繁踢出加入消费者组造成消息积压。另外生产端ACK参数设置为1，每次Leader切换时就会发生数据丢失。数据丢失导致预警不准确和链路拼接不完整，数据积压导致预警不及时。经过优化后数据丢失和积压情况得明显改善，由原来千分之三的丢失率降低到万分之一，并且无积压情况发生。具体措施如下：
>
> 1、将生产者Ack参数设置为-1，确保所有副本均完成消息同步。
>
> 2、集群扩容（增加Broker）来增加集群吞吐量，进而降低单台Broker的压力。虚机磁盘IO优化，将原来的单块盘调整为多块盘在创建LV时将磁盘做条带化来增加磁盘IO能力。扩容后需要将已有的分区重新均衡到每台机器。
> 3、适当增加主题Partition数量并增加消费者增强数据处理能力。
>
> 4、主题拆分，系统设计之初第一次报文转换是将多个主题的数据经过Flink计算处理后存入单一主题，这也是造成数据积压的原因之一。拆分后虽然增加了业务处理逻辑，但大大降低了单一主题的数据量，可以使生产者和消费者可以达到读写平衡（零IO数据交换），降低数据积压风险。

> 实时数据处理-客户服务
>
> 实时计算在证券公司除了在智能运维方面的应用外，在客户服务领域也有大量应用。比如新闻推荐、产品推荐、客户实时资产展示等。客户实时资产是实时统计客户在各交易系统的资产变动情况。架构图如图3所示：
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_png/GI1YdwAnLsUUazkd0VgeoKOU89BiaWfh3skEkvYmic6jnp7XRm8Zp9fYk8JO4NTibT6Ol3ibw3negSQo8yq7uSbEcg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
> 图 3 实时资产架构图
>
> 如图所示，Attunity负责将各交易系统数据库的变更抽象为消息实时推送到Kafka，再使用Spark Streaming对Kafka消息汇总计算后存入Redis，并以接口的形式提供给公司业务系统。
>
> 由于实时资产系统是抓取交易系统的变更数据，对消息顺序性要求非常严格。Kafka由于其分布式的原因，只能保证单个分区内消息的时序性，对于多分区的主题而言无法保证消费时的顺序性。在系统仿真测试时遇到了由于非顺序消费导致的客户资产计算不正确的问题。测试时使用某位客户下单购买某只股票1000股且全部成交，但是实时资产系统中只成交600股。经过后续问题排查发现该笔买单分两次成交，第一次成交600股，第二次成交400股。一次买入被拆分成两条消息推送到Kafka（一条insert，一条update），而且两条消息被持久化到不同的分区上。在数据处理时先处理Update消息后处理Insert消息，导致实时资产系统只有600股成交。消息被发送到两个分区是导致该问题发生的根本原因。
>
> 解决该问题途径是将一个客户对一只股票的所有买卖操作发送到同一个分区内，来保证客户对股票操作的有序性。做法是在生产消息时指定消息的Key，该场景中使用客户号、股票代码、市场代码作为Key。相同Key的消息会被发送到同一个分区，消费时顺序性得到保证，问题得以解决。

> 消息系统
>
> Kafka作为消息系统使用时通常应用在流程类系统、订单类系统，实现生产者和消费者解耦、缓冲消息、异步处理等功能。中信建投的公司运营平台，通过自动化流程实现客户服务、客户运营。该平台应用Kafka实现了消息异步处理和流程处理，比如平台获取目标客户后缓存到Kafka中，再由消费者程序为客户发送服务提醒短信或者电话、短信回访等客户服务。系统遇到的最大问题是重复消费，重复消费会导致客户被多次服务，不仅给公司带来资源浪费还使客户体验不友好。解决重复消费就是增加消费端的幂等校验，本案例中采用Redis作为解决方案。如图4所示。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_png/GI1YdwAnLsUUazkd0VgeoKOU89BiaWfh3N8oOsd0oh7KDNSibia6cLMhPP26pTSWf4bZdxhWiaBViaqr0PrhzTyA8bA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
> 图 4 幂等校验流程图
>
> 
>
> 图4中，消费者程序在Poll消息后需要判断每条消息在Redis中是否存在，如果不存在就进行客户服务并将相关信息存入Redis。如果获取的消息在Redis中已经存在，则将该条消息做丢弃处理。在数据处理异常的情况下需要增加告警机制，便于及时进行人工处理。另外，消费者程序Offset提交需要改为手动（同步提交方式），并适当调大超时时间。Offset自动提交在消费者发生异常或者消费超时的情况下会导致数据丢失。
